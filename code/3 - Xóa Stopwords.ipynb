{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Đọc dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%cd /content/drive/MyDrive/Data Mining Field-oriented/data/consolidated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "file_name = f\"cleaned_articles_training.tsv\"\n",
    "try:\n",
    "    df = pd.read_csv(file_name, sep=\"\\t\", encoding=\"utf-8\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"File {file_name} not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xóa stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "vietnamese_stopwords = pd.read_csv('/content/drive/MyDrive/Data Mining Field-oriented/consolidated/stop words/vietnamese-stopwords-dash.txt', encoding='utf-8', header=None)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(text, stopwords):\n",
    "    words = text.split()\n",
    "\n",
    "    filtered_words = [word for word in words if word.lower() not in stopwords]\n",
    "    return ' '.join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess(text, vietnamese_stopwords):\n",
    "    text = str(text)\n",
    "    pattern_keep = r'(?<=[a-zA-Z0-9])(\\.|,)(?=[a-zA-Z0-9])|(?<=[a-zA-Z])\\.(?=\\s|,|$)'\n",
    "\n",
    "    # isbn_pattern = r'\\b(?:\\d{9}[\\dXx]|\\d{13})\\b'\n",
    "    # ip_pattern = r'\\b(?:\\d{1,3}\\.){3}\\d{1,3}\\b|\\b(?:[a-fA-F0-9]{1,4}:){7}[a-fA-F0-9]{1,4}\\b'\n",
    "\n",
    "    text = re.sub(pattern_keep, r'\\1', text)\n",
    "\n",
    "    pattern_remove = r'[.,](?=\\s|$|[^a-zA-Z0-9])'\n",
    "    cleaned_text = re.sub(pattern_remove, ' ', text)\n",
    "\n",
    "    cleaned_text = re.sub(r'\\s{2,}', ' ', cleaned_text)\n",
    "    cleaned_text = re.sub(r'[/-]', ' ', cleaned_text)\n",
    "    cleaned_text = re.sub(r'\\b\\d+\\b', '', cleaned_text)\n",
    "    cleaned_text = re.sub(r'\\s{2,}', ' ', cleaned_text)\n",
    "\n",
    "    cleaned_text = remove_stopwords(cleaned_text, vietnamese_stopwords)\n",
    "\n",
    "    return cleaned_text.strip().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df['content'] = df['content'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv(f'/content/drive/MyDrive/Data Mining Field-oriented/consolidated/cleaned_articles_training.tsv', sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
